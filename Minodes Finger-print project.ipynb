{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minodes Fingerprint to Zone Classification Challenge (v3)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "At Minodes, we provide insights to retailers using WiFi Analytics. Insights are derived by analyzing the location of people's smartphones during their visits.\n",
    "\n",
    "How does it work? We install a set of WiFi routers (so-called \"nodes\") with a custom firmware inside or close to the areas to be monitored. Nodes collect the signal strength (`RSSI`) of WiFi probe requests sent regularly by smartphones (so-called \"observations\"). Observations are then used to estimate the position of smartphones: Let `RSSI(N,X)` be a function that returns the signal strength of probe request `X` observed from node `N` (measured in dBm: `0` is strongest signal strength, `-100` is weakest signal strength, extremes are seldom reached). The set of observations `RSSI(Ni,X)` for all nodes `i` is called \"fingerprint\" and constitutes a radio signature of the smartphone correlated (non linearly) to its position in space (a distance of few meters translates to a signal strength within `[0,-30]`). Stores are manually partitioned into regions (so-called \"zones\"), e.g. \"entrance\" and \"checkout area\". Fingerprints and zones are used as features and prediction classes, respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "This archive contains a dataset in CSV format located at `data/fingerprints_gt_ver3.csv`. The dataset represents a large deployment in a mall (three floors), and has been generated by walking inside each zone with a set of phones, labeling fingerprints manually with their corresponding zone. Nodes are located at the exterior of the entrance of the stores, and not inside the stores. Zones map to shops, aisles, and surrounding areas. The dataset is structured as follows:\n",
    "\n",
    "| fr_observation_time  | fr_values  | fr_mac_address_id | zo_name  |\n",
    "| -------------------- | ---------- | ----------------- | ---------|  \n",
    "| 2015-12-08 10:00:13  | {'9': '-83', '13': '-67', '33': '-62', '101': ...  | 3192369 | Zone 355  |\n",
    "| 2015-12-08 10:00:13  | {'12': '-69', '33': '-61', '128': '-68', '276'...  | 2002427 | Zone 355  |\n",
    "\n",
    "Description of the fields:\n",
    "\n",
    "* `fr_observation_time`: first timestamp in ascending order of the observations aggregated into the fingerprint (aggregation spans 1 second by default, to accommodate time desynchronization issues on the nodes)\n",
    "* `fr_values`: fingerprint, represented as a dictionary  {`node_id`: `signal_strength`, ...}. If a node ID is not present,  you can assume that its associated signal strength is `-100`\n",
    "* `fr_mac_address_id`: unique id of the mac address of the phone that emitted the corresponding probe request\n",
    "* `zo_name`: zone name (class to be predicted). Zone names are strings containing numbers and do not have a direct semantic meaning.\n",
    "\n",
    "Some statistics about the dataset:\n",
    "\n",
    "* `343449` unique fingerprints (rows in the CSV file, excluding header line)\n",
    "* `19` unique mac address ids. That means that 19 different phones were used to collect the dataset\n",
    "* `449` unique zones\n",
    "* `261` unique nodes\n",
    "* On average, each node is present in `23224` fingerprints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "Given a fingerprint, predict its corresponding zone with a classifier.\n",
    "The dataset must be used for training and testing the classifier.\n",
    "Assess your solution by reporting confusion matrix, precision, recall and F1 score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## solution part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Tiny Ants\\\\Documents'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fingerprints = pd.read_csv('fingerprints_gt_ver3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 343449 entries, 0 to 343448\n",
      "Data columns (total 4 columns):\n",
      "fr_observation_time    343449 non-null object\n",
      "fr_values              343449 non-null object\n",
      "fr_mac_address_id      343449 non-null int64\n",
      "zo_name                343449 non-null object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 10.5+ MB\n"
     ]
    }
   ],
   "source": [
    "fingerprints.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fr_mac_address_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.434490e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.012072e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.236813e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.904420e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.066320e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.192369e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.819582e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.819586e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fr_mac_address_id\n",
       "count       3.434490e+05\n",
       "mean        5.012072e+06\n",
       "std         4.236813e+06\n",
       "min         3.904420e+05\n",
       "25%         9.066320e+05\n",
       "50%         3.192369e+06\n",
       "75%         9.819582e+06\n",
       "max         9.819586e+06"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fingerprints.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fr_observation_time</th>\n",
       "      <th>fr_values</th>\n",
       "      <th>fr_mac_address_id</th>\n",
       "      <th>zo_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-08 10:00:13</td>\n",
       "      <td>{'12': '-69', '33': '-61', '128': '-68', '276'...</td>\n",
       "      <td>2002427</td>\n",
       "      <td>Zone 355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-08 10:00:13</td>\n",
       "      <td>{'9': '-83', '13': '-67', '33': '-62', '101': ...</td>\n",
       "      <td>3192369</td>\n",
       "      <td>Zone 355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-08 10:00:14</td>\n",
       "      <td>{'9': '-83', '10': '-77', '11': '-85', '12': '...</td>\n",
       "      <td>2002427</td>\n",
       "      <td>Zone 355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-08 10:00:14</td>\n",
       "      <td>{'9': '-86', '10': '-83', '11': '-87', '12': '...</td>\n",
       "      <td>3192369</td>\n",
       "      <td>Zone 355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-12-08 10:00:15</td>\n",
       "      <td>{'10': '-76', '11': '-86', '12': '-65', '13': ...</td>\n",
       "      <td>480806</td>\n",
       "      <td>Zone 355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fr_observation_time                                          fr_values  \\\n",
       "0  2015-12-08 10:00:13  {'12': '-69', '33': '-61', '128': '-68', '276'...   \n",
       "1  2015-12-08 10:00:13  {'9': '-83', '13': '-67', '33': '-62', '101': ...   \n",
       "2  2015-12-08 10:00:14  {'9': '-83', '10': '-77', '11': '-85', '12': '...   \n",
       "3  2015-12-08 10:00:14  {'9': '-86', '10': '-83', '11': '-87', '12': '...   \n",
       "4  2015-12-08 10:00:15  {'10': '-76', '11': '-86', '12': '-65', '13': ...   \n",
       "\n",
       "   fr_mac_address_id   zo_name  \n",
       "0            2002427  Zone 355  \n",
       "1            3192369  Zone 355  \n",
       "2            2002427  Zone 355  \n",
       "3            3192369  Zone 355  \n",
       "4             480806  Zone 355  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fingerprints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fr_observation_time', 'fr_values', 'fr_mac_address_id', 'zo_name'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fingerprints.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Train-Test Split\n",
    "\n",
    "Random seed =101\n",
    "\n",
    "Before splitting the data as Train and Test, we are gonna understand the features and do some pre-processing like adding or removing features. Once we have proper data structure we can then spilt them with the help of sklearn library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data_dict = fingerprints.drop('zo_name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343449, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_dict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fr_observation_time</th>\n",
       "      <th>fr_values</th>\n",
       "      <th>fr_mac_address_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-08 10:00:13</td>\n",
       "      <td>{'12': '-69', '33': '-61', '128': '-68', '276'...</td>\n",
       "      <td>2002427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-08 10:00:13</td>\n",
       "      <td>{'9': '-83', '13': '-67', '33': '-62', '101': ...</td>\n",
       "      <td>3192369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-08 10:00:14</td>\n",
       "      <td>{'9': '-83', '10': '-77', '11': '-85', '12': '...</td>\n",
       "      <td>2002427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-08 10:00:14</td>\n",
       "      <td>{'9': '-86', '10': '-83', '11': '-87', '12': '...</td>\n",
       "      <td>3192369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-12-08 10:00:15</td>\n",
       "      <td>{'10': '-76', '11': '-86', '12': '-65', '13': ...</td>\n",
       "      <td>480806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fr_observation_time                                          fr_values  \\\n",
       "0  2015-12-08 10:00:13  {'12': '-69', '33': '-61', '128': '-68', '276'...   \n",
       "1  2015-12-08 10:00:13  {'9': '-83', '13': '-67', '33': '-62', '101': ...   \n",
       "2  2015-12-08 10:00:14  {'9': '-83', '10': '-77', '11': '-85', '12': '...   \n",
       "3  2015-12-08 10:00:14  {'9': '-86', '10': '-83', '11': '-87', '12': '...   \n",
       "4  2015-12-08 10:00:15  {'10': '-76', '11': '-86', '12': '-65', '13': ...   \n",
       "\n",
       "   fr_mac_address_id  \n",
       "0            2002427  \n",
       "1            3192369  \n",
       "2            2002427  \n",
       "3            3192369  \n",
       "4             480806  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_dict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the X Input Features:\n",
    " getting the x features from the fr_values and concatinating the with the rest of others features.\n",
    " Since the output y labels depend only on the strengh of the signals (i.e) fr_values, we are gonna drop other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data_dict['fr_values'] = x_data_dict['fr_values'].apply(lambda x: dict(eval(x)))\n",
    "temp = x_data_dict['fr_values'].apply(pd.Series)\n",
    "temp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data_dict = pd.concat([x_data_dict, temp], axis=1).drop('fr_values', axis=1)\n",
    "x_data_dict;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Input Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data_dict = x_data_dict.drop(['fr_observation_time', 'fr_mac_address_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing all the 'NaN' with '-100', since all the NaN means Zero signal [signal strength = -100 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>89</th>\n",
       "      <th>9</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-64</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-83</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-100</td>\n",
       "      <td>-77</td>\n",
       "      <td>-69</td>\n",
       "      <td>-71</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-85</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-83</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-79</td>\n",
       "      <td>-74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-100</td>\n",
       "      <td>-83</td>\n",
       "      <td>-65</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-87</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-86</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-100</td>\n",
       "      <td>-76</td>\n",
       "      <td>-65</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-86</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 261 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1    10   101   102   103   104   105   107   109    11  ...     89  \\\n",
       "0  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  ...   -100   \n",
       "1  -100  -100   -64  -100  -100  -100  -100  -100  -100  -100  ...   -100   \n",
       "2  -100   -77   -69   -71  -100  -100  -100  -100  -100   -85  ...   -100   \n",
       "3  -100   -83   -65  -100  -100  -100  -100  -100  -100   -87  ...   -100   \n",
       "4  -100   -76   -65  -100  -100  -100  -100  -100  -100   -86  ...   -100   \n",
       "\n",
       "      9    90    91    92    93    94    97    98    99  \n",
       "0  -100  -100  -100  -100  -100  -100  -100  -100  -100  \n",
       "1   -83  -100  -100  -100  -100  -100  -100  -100  -100  \n",
       "2   -83  -100  -100  -100  -100  -100  -100   -79   -74  \n",
       "3   -86  -100  -100  -100  -100  -100  -100  -100   -80  \n",
       "4  -100  -100  -100  -100  -100  -100  -100  -100  -100  \n",
       "\n",
       "[5 rows x 261 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_dict = x_data_dict.fillna(-100)\n",
    "x_data_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1', '10', '101', '102', '103', '104', '105', '107', '109', '11',\n",
       "       ...\n",
       "       '89', '9', '90', '91', '92', '93', '94', '97', '98', '99'],\n",
       "      dtype='object', length=261)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = x_data_dict.columns\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y_labels\n",
    "Converting the strings to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fingerprints['zones'] = fingerprints.zo_name.str[5:8]\n",
    "fingerprints['zones'] = fingerprints['zones'].astype(str).astype(int)\n",
    "# for label encoding\n",
    "y_labels1 = pd.DataFrame(data= fingerprints['zones']) \n",
    "y_labels1['zones'] = y_labels1['zones'].astype(str).astype(int)\n",
    "# for one hot encoding, for later use\n",
    "y_labels = pd.DataFrame(data= fingerprints['zones']) \n",
    "y_labels['zones'] = y_labels['zones'].astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343449, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zones\n",
       "0    355\n",
       "1    355\n",
       "2    355\n",
       "3    355\n",
       "4    355"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "dummy = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Label encode\n",
    "y_labels1.values[:,0] = dummy.fit_transform(y_labels1.values[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343449, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# converting y labels to data frame if needed\n",
    "#df = pd.DataFrame(y_labels, index=range(y_labels.shape[0]), columns=range(y_labels.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Train Split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data_dict, y_labels1, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>89</th>\n",
       "      <th>9</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76780</th>\n",
       "      <td>-100</td>\n",
       "      <td>-81</td>\n",
       "      <td>-100</td>\n",
       "      <td>-58</td>\n",
       "      <td>-50</td>\n",
       "      <td>-69</td>\n",
       "      <td>-64</td>\n",
       "      <td>-82</td>\n",
       "      <td>-100</td>\n",
       "      <td>-81</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-87</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318851</th>\n",
       "      <td>-80</td>\n",
       "      <td>-51</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-66</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-65</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-77</td>\n",
       "      <td>-73</td>\n",
       "      <td>-70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327610</th>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-85</td>\n",
       "      <td>-100</td>\n",
       "      <td>-69</td>\n",
       "      <td>-72</td>\n",
       "      <td>-61</td>\n",
       "      <td>-58</td>\n",
       "      <td>-57</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168927</th>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327537</th>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 261 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1    10   101   102   103   104   105   107   109    11  ...   \\\n",
       "76780   -100   -81  -100   -58   -50   -69   -64   -82  -100   -81  ...    \n",
       "318851   -80   -51  -100  -100  -100  -100  -100  -100  -100   -66  ...    \n",
       "327610  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  ...    \n",
       "168927  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  ...    \n",
       "327537  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  ...    \n",
       "\n",
       "          89     9    90    91    92    93    94    97    98    99  \n",
       "76780   -100   -87  -100  -100  -100  -100  -100  -100  -100  -100  \n",
       "318851  -100   -65  -100  -100  -100  -100  -100   -77   -73   -70  \n",
       "327610   -85  -100   -69   -72   -61   -58   -57  -100  -100  -100  \n",
       "168927  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  \n",
       "327537  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  \n",
       "\n",
       "[5 rows x 261 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240414, 261)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240414, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103035, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tiny Ants\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "gauss_naive = GaussianNB().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19483670597369826"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss_naive_accuracy = gauss_naive.score(x_test, y_test)\n",
    "gauss_naive_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gauss_naive_predictions = gauss_naive.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0,  0, ...,  0,  0,  0],\n",
       "       [37, 37, 13, ...,  0,  0,  0],\n",
       "       [ 1,  0, 11, ...,  0,  0,  0],\n",
       "       ..., \n",
       "       [ 0,  0,  0, ..., 45,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0, 21,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0, 50]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss_naive_cm = confusion_matrix(y_test, gauss_naive_predictions)\n",
    "gauss_naive_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tiny Ants\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Tiny Ants\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'             precision    recall  f1-score   support\\n\\n          0       0.02      1.00      0.03         1\\n          1       0.17      0.42      0.24        89\\n          2       0.03      0.92      0.05        12\\n          3       0.05      0.11      0.07       195\\n          4       0.27      0.50      0.35       316\\n          5       0.24      0.09      0.13       374\\n          6       0.35      0.31      0.33       102\\n          7       0.01      0.56      0.02        16\\n          8       0.34      0.14      0.20       147\\n          9       0.47      0.12      0.19       136\\n         10       0.28      0.28      0.28       360\\n         11       0.49      0.06      0.11       318\\n         12       0.22      0.01      0.01       363\\n         13       0.49      0.13      0.21       397\\n         14       0.20      0.49      0.29       347\\n         15       0.37      0.09      0.15       359\\n         16       0.50      0.00      0.01       320\\n         17       0.20      0.26      0.23       329\\n         18       0.17      0.01      0.01       276\\n         19       0.51      0.52      0.52       235\\n         20       0.46      0.51      0.48       287\\n         21       0.53      0.42      0.47       300\\n         22       0.17      0.15      0.16       230\\n         23       0.24      0.26      0.25       250\\n         24       0.12      0.06      0.08       234\\n         25       0.27      0.50      0.35       240\\n         26       0.38      0.13      0.20       234\\n         27       0.37      0.28      0.32       215\\n         28       0.28      0.10      0.14       229\\n         29       0.33      0.37      0.35       257\\n         30       0.00      0.00      0.00       306\\n         31       0.56      0.03      0.06       303\\n         32       0.26      0.03      0.05       361\\n         33       0.06      0.82      0.11       114\\n         34       0.07      0.01      0.02       199\\n         35       0.11      0.31      0.16       173\\n         36       0.23      0.19      0.20       177\\n         37       0.20      0.83      0.32       212\\n         38       0.16      0.18      0.17       181\\n         39       0.17      0.51      0.25       152\\n         40       0.11      0.50      0.18       209\\n         41       0.10      0.02      0.03       210\\n         42       0.13      0.08      0.10       194\\n         43       0.00      0.00      0.00       180\\n         44       0.06      0.03      0.04       277\\n         45       0.28      0.88      0.42       220\\n         46       0.19      0.46      0.27       171\\n         47       0.75      0.02      0.03       171\\n         48       0.39      0.22      0.28       197\\n         49       0.49      0.47      0.48       235\\n         50       0.24      0.08      0.12       294\\n         51       0.28      0.13      0.18       282\\n         52       0.15      0.22      0.18       156\\n         53       0.17      0.71      0.28       115\\n         54       0.20      0.32      0.24       174\\n         55       0.17      0.91      0.28        87\\n         56       0.13      0.10      0.11       187\\n         57       0.09      0.04      0.06       163\\n         58       0.08      0.17      0.11        84\\n         59       0.07      0.95      0.13        19\\n         60       0.23      0.07      0.11       184\\n         61       0.03      0.23      0.05        44\\n         62       0.45      0.03      0.06       292\\n         63       0.18      0.01      0.03       291\\n         64       0.49      0.06      0.11       300\\n         65       0.54      0.06      0.10       266\\n         66       0.26      0.16      0.20       347\\n         67       0.47      0.53      0.50       160\\n         68       0.13      0.40      0.20       134\\n         69       0.29      0.51      0.37       184\\n         70       0.23      0.37      0.29       194\\n         71       0.35      0.37      0.36       294\\n         72       0.47      0.08      0.14       514\\n         73       0.23      0.02      0.03       300\\n         74       0.27      0.09      0.13       334\\n         75       0.27      0.24      0.26       323\\n         76       0.42      0.19      0.26       280\\n         77       0.27      0.29      0.28       232\\n         78       0.20      0.08      0.11       277\\n         79       0.13      0.38      0.19       308\\n         80       0.26      0.42      0.32       295\\n         81       0.50      0.04      0.08       272\\n         82       0.28      0.19      0.23       284\\n         83       0.33      0.01      0.01       338\\n         84       0.23      0.36      0.28       207\\n         85       0.23      0.29      0.26       215\\n         86       0.13      0.46      0.20       124\\n         87       0.11      0.40      0.17       266\\n         88       0.20      0.90      0.33       346\\n         89       0.07      0.07      0.07       344\\n         90       0.93      0.24      0.38       353\\n         91       0.45      0.56      0.50       362\\n         92       0.08      0.21      0.11       296\\n         93       0.15      0.04      0.07       327\\n         94       0.25      0.21      0.23       342\\n         95       0.22      0.13      0.16       333\\n         96       0.26      0.07      0.11       328\\n         97       0.26      0.33      0.29       217\\n         98       0.10      0.14      0.12       266\\n         99       0.07      0.20      0.10       188\\n        100       0.12      1.00      0.22       103\\n        101       0.12      0.30      0.17       254\\n        102       0.10      0.13      0.11       248\\n        103       0.55      0.09      0.15       335\\n        104       0.14      0.09      0.11       253\\n        105       0.24      0.49      0.32       220\\n        106       0.46      0.07      0.12       355\\n        107       0.18      0.17      0.17       259\\n        108       0.43      0.12      0.19       328\\n        109       0.11      0.73      0.19       228\\n        110       0.14      0.20      0.16       209\\n        111       0.89      0.18      0.30       342\\n        112       0.23      0.06      0.10       349\\n        113       0.30      0.48      0.37       383\\n        114       0.98      0.45      0.62       287\\n        115       0.05      0.01      0.01       138\\n        116       0.62      0.10      0.17       304\\n        117       0.11      0.03      0.04       317\\n        118       0.55      0.37      0.44       156\\n        119       0.04      0.95      0.08        37\\n        120       0.45      0.47      0.46       258\\n        121       0.03      0.01      0.01       230\\n        122       0.06      1.00      0.11        28\\n        123       0.13      0.30      0.19       202\\n        124       0.01      0.05      0.01        20\\n        125       0.06      0.04      0.05       227\\n        126       0.07      0.20      0.10       120\\n        127       0.42      0.03      0.05       345\\n        128       0.23      0.13      0.17       261\\n        129       0.35      0.15      0.21       279\\n        130       0.47      0.20      0.29       279\\n        131       0.49      0.47      0.48       273\\n        132       0.72      0.04      0.07       367\\n        133       0.60      0.03      0.05       337\\n        134       0.54      0.18      0.27       337\\n        135       0.51      0.15      0.23       306\\n        136       0.15      0.07      0.10       284\\n        137       0.22      0.06      0.10       329\\n        138       0.31      0.11      0.16       227\\n        139       0.69      0.02      0.05       383\\n        140       0.34      0.13      0.19       313\\n        141       0.21      0.06      0.09       333\\n        142       0.22      0.17      0.19       271\\n        143       0.68      0.16      0.26       293\\n        144       0.36      0.30      0.33       287\\n        145       0.68      0.09      0.17       243\\n        146       0.41      0.28      0.33       265\\n        147       0.24      0.12      0.16       257\\n        148       0.12      0.13      0.13       177\\n        149       0.13      0.29      0.18       150\\n        150       0.13      0.13      0.13        76\\n        151       0.27      0.03      0.06       196\\n        152       0.16      0.99      0.27        74\\n        153       0.00      0.00      0.00       226\\n        154       0.01      0.02      0.01        49\\n        155       0.06      0.06      0.06        93\\n        156       0.03      0.14      0.05       210\\n        157       0.14      0.05      0.07       213\\n        158       0.03      0.48      0.06        33\\n        159       0.20      0.03      0.05       274\\n        160       0.04      0.10      0.05       275\\n        161       0.13      0.03      0.05       221\\n        162       0.03      0.30      0.05        47\\n        163       0.15      0.13      0.14       180\\n        164       0.10      0.03      0.04       231\\n        165       0.06      0.80      0.10        30\\n        166       0.11      0.22      0.14       182\\n        167       0.06      0.46      0.11       115\\n        168       0.07      0.01      0.01       186\\n        169       0.08      0.05      0.06       262\\n        170       0.24      0.10      0.14       210\\n        171       0.28      0.58      0.38       209\\n        172       0.07      0.32      0.12       102\\n        173       0.29      0.06      0.10       152\\n        174       0.34      0.27      0.30       153\\n        175       0.11      0.13      0.12       231\\n        176       0.34      0.23      0.27       328\\n        177       0.11      0.95      0.20        22\\n        178       0.03      0.31      0.06        62\\n        179       0.21      0.13      0.16       293\\n        180       0.17      0.19      0.18       256\\n        181       0.37      0.10      0.16       212\\n        182       0.22      0.08      0.12       207\\n        183       0.16      0.20      0.18       139\\n        184       0.50      0.11      0.18       147\\n        185       0.72      0.17      0.27       184\\n        186       0.27      0.26      0.27       151\\n        187       0.10      0.14      0.11        71\\n        188       0.51      0.13      0.20       273\\n        189       0.10      0.32      0.15        82\\n        190       0.11      0.73      0.20       126\\n        191       0.06      0.13      0.08        61\\n        192       0.24      0.76      0.37       190\\n        193       0.54      0.09      0.16       209\\n        194       0.70      0.03      0.06       228\\n        195       0.51      0.15      0.23       236\\n        196       0.20      0.31      0.24       205\\n        197       0.05      0.14      0.08        59\\n        198       0.00      0.00      0.00         0\\n        199       0.01      0.07      0.02        29\\n        200       0.00      0.00      0.00         1\\n        201       0.22      0.05      0.08       269\\n        202       0.07      0.84      0.13       118\\n        203       0.05      1.00      0.10         4\\n        204       0.27      0.47      0.34       240\\n        205       0.11      0.20      0.14       342\\n        206       0.29      0.21      0.25       258\\n        207       0.50      0.04      0.08       250\\n        208       0.22      0.05      0.08       277\\n        209       0.78      0.24      0.36       323\\n        210       0.17      0.12      0.14       201\\n        211       0.21      0.07      0.11       212\\n        212       0.97      0.23      0.38       274\\n        213       0.27      0.43      0.33       141\\n        214       0.57      0.15      0.24       349\\n        215       0.25      0.14      0.18       346\\n        216       0.38      0.58      0.46       343\\n        217       0.05      0.48      0.09        33\\n        218       0.00      0.05      0.01        59\\n        219       0.41      0.20      0.26       251\\n        220       0.59      0.28      0.38       330\\n        221       0.49      0.26      0.34       311\\n        222       0.57      0.21      0.31       324\\n        223       0.23      0.07      0.10       198\\n        224       0.01      0.54      0.03        13\\n        225       0.14      0.01      0.02       241\\n        226       0.21      0.23      0.22       265\\n        227       0.40      0.48      0.44       260\\n        228       0.38      0.11      0.17       206\\n        229       0.16      0.08      0.11       182\\n        230       0.00      0.00      0.00       175\\n        231       0.13      0.43      0.20       199\\n        232       0.16      0.13      0.15       215\\n        233       0.23      0.60      0.33       299\\n        234       0.32      0.20      0.24       338\\n        235       0.72      0.06      0.11       351\\n        236       0.34      0.18      0.23       325\\n        237       0.58      0.04      0.08       341\\n        238       0.26      0.07      0.11       345\\n        239       0.22      0.01      0.01       286\\n        240       0.14      0.14      0.14       353\\n        241       0.06      0.07      0.06        59\\n        242       0.02      0.16      0.03        31\\n        243       0.32      0.03      0.06       292\\n        244       0.13      0.05      0.07       213\\n        245       0.10      0.14      0.12       315\\n        246       0.13      0.28      0.18       120\\n        247       0.06      0.92      0.12        12\\n        248       0.15      0.17      0.16       156\\n        249       0.57      0.01      0.02       321\\n        250       0.29      0.94      0.45       209\\n        251       0.61      0.49      0.55       192\\n        252       0.05      0.06      0.05        49\\n        253       0.52      0.08      0.14       212\\n        254       0.05      0.89      0.10         9\\n        255       0.10      0.25      0.14        52\\n        256       0.08      0.27      0.13        70\\n        257       0.28      0.10      0.15       190\\n        258       0.77      0.21      0.32       224\\n        259       0.62      0.08      0.13       172\\n        260       0.21      0.05      0.09       130\\n        261       0.17      0.11      0.14       183\\n        262       0.19      0.52      0.28       233\\n        263       0.26      0.03      0.05       248\\n        264       0.17      0.05      0.08       205\\n        265       0.38      0.29      0.33       234\\n        266       0.24      0.14      0.18       186\\n        267       0.34      0.78      0.48       266\\n        268       0.33      0.94      0.49       310\\n        269       0.53      0.17      0.26       335\\n        270       0.62      0.11      0.18       269\\n        271       0.34      0.16      0.22       313\\n        272       0.07      0.35      0.12       227\\n        273       0.08      0.07      0.07       123\\n        274       0.21      0.71      0.32       174\\n        275       0.46      0.10      0.16       281\\n        276       0.60      0.01      0.02       325\\n        277       0.59      0.66      0.62       313\\n        278       0.39      0.12      0.18       301\\n        279       0.19      0.11      0.14       225\\n        280       0.52      0.14      0.22       327\\n        281       0.52      0.11      0.18       233\\n        282       0.60      0.10      0.18       229\\n        283       0.37      0.18      0.25       332\\n        284       0.15      0.09      0.11       347\\n        285       0.41      0.14      0.21       333\\n        286       0.13      0.26      0.17       350\\n        287       0.10      0.30      0.14       308\\n        288       0.10      0.22      0.13       225\\n        289       0.17      0.14      0.15       218\\n        290       0.04      0.69      0.07        91\\n        291       0.15      0.01      0.03       212\\n        292       0.14      0.04      0.06       249\\n        293       0.27      0.07      0.11       233\\n        294       0.31      0.17      0.22       253\\n        295       0.43      0.04      0.07       234\\n        296       0.44      0.18      0.26       229\\n        297       0.44      0.09      0.15       264\\n        298       0.28      0.06      0.11       231\\n        299       0.11      0.30      0.16       268\\n        300       0.53      0.05      0.08       220\\n        301       0.28      0.17      0.21       193\\n        302       0.43      0.37      0.40       297\\n        303       0.61      0.17      0.26       329\\n        304       0.24      0.10      0.14       215\\n        305       0.40      0.12      0.18       224\\n        306       0.46      0.11      0.18       232\\n        307       0.30      0.03      0.05       277\\n        308       0.44      0.15      0.23       230\\n        309       0.30      0.10      0.15       237\\n        310       0.00      0.00      0.00       237\\n        311       0.14      0.72      0.23        47\\n        312       0.29      0.06      0.10        63\\n        313       0.13      0.02      0.04       142\\n        314       0.26      0.03      0.05       248\\n        315       0.26      0.04      0.06       274\\n        316       0.35      0.01      0.02       509\\n        317       0.24      0.02      0.03       487\\n        318       0.26      0.04      0.07       296\\n        319       0.04      0.22      0.07       199\\n        320       0.00      0.00      0.00       454\\n        321       0.24      0.19      0.21       254\\n        322       0.00      0.00      0.00       267\\n        323       0.40      0.06      0.11       223\\n        324       0.43      0.13      0.20       255\\n        325       0.28      0.04      0.08       293\\n        326       0.03      0.83      0.05         6\\n        327       0.36      0.17      0.23       159\\n        328       0.47      0.25      0.33       274\\n        329       0.67      0.04      0.08       277\\n        330       0.08      0.22      0.12       156\\n        331       0.24      0.09      0.13       139\\n        332       0.24      0.17      0.20       120\\n        333       0.33      0.06      0.10       138\\n        334       0.00      0.00      0.00       162\\n        335       0.15      0.06      0.09       143\\n        336       0.16      0.09      0.12       176\\n        337       0.20      0.02      0.04       263\\n        338       0.24      0.21      0.23       286\\n        339       0.28      0.03      0.05       343\\n        340       0.34      0.04      0.07       328\\n        341       0.33      0.41      0.36       328\\n        342       0.27      0.20      0.23       314\\n        343       0.37      0.25      0.30       353\\n        344       0.19      0.13      0.15       225\\n        345       0.21      0.51      0.30       166\\n        346       0.89      0.12      0.22       253\\n        347       0.29      0.18      0.22       235\\n        348       0.20      0.06      0.10       189\\n        349       0.39      0.18      0.25       158\\n        350       0.44      0.23      0.30       210\\n        351       0.18      0.21      0.19       284\\n        352       0.39      0.21      0.27       159\\n        353       0.10      0.38      0.16        65\\n        354       0.32      0.20      0.25       344\\n        355       0.25      0.31      0.28       210\\n        356       0.43      0.57      0.49       216\\n        357       0.19      0.06      0.09       319\\n        358       0.29      0.03      0.06       237\\n        359       0.26      0.07      0.11       288\\n        360       0.44      0.35      0.39       209\\n        361       0.36      0.11      0.17       218\\n        362       0.22      0.98      0.35       207\\n        363       0.43      0.26      0.32       193\\n        364       0.14      0.16      0.15       215\\n        365       0.35      0.09      0.15       332\\n        366       0.37      0.07      0.12       344\\n        367       0.16      0.21      0.18       165\\n        368       0.25      0.16      0.19       187\\n        369       0.64      0.08      0.14       231\\n        370       0.50      0.70      0.58       231\\n        371       0.46      0.36      0.40       226\\n        372       0.16      0.32      0.22       155\\n        373       0.19      0.01      0.02       240\\n        374       0.15      0.40      0.22       209\\n        375       0.39      0.23      0.29       237\\n        376       0.24      0.07      0.10       331\\n        377       0.07      0.88      0.14       171\\n        378       0.11      0.41      0.17       171\\n        379       0.10      0.14      0.12       148\\n        380       0.23      0.08      0.12       167\\n        381       0.22      0.16      0.19       161\\n        382       0.19      0.43      0.26       157\\n        383       0.13      0.11      0.12       217\\n        384       0.07      0.56      0.13       119\\n        385       0.25      0.17      0.20       334\\n        386       0.33      0.13      0.19       270\\n        387       0.67      0.02      0.03       228\\n        388       0.57      0.13      0.21       332\\n        389       0.17      0.05      0.07       344\\n        390       0.93      0.06      0.12       394\\n        391       0.20      0.07      0.10       322\\n        392       0.91      0.12      0.22       162\\n        393       0.58      0.09      0.16       304\\n        394       0.23      0.11      0.15       247\\n        395       0.16      0.12      0.14       288\\n        396       0.36      0.07      0.12       202\\n        397       0.17      0.04      0.06       175\\n        398       0.42      0.06      0.11       207\\n        399       0.45      0.26      0.33       168\\n        400       0.30      0.16      0.20       283\\n        401       0.34      0.39      0.36       321\\n        402       0.62      0.15      0.24       312\\n        403       0.33      0.64      0.44       149\\n        404       0.41      0.20      0.27       250\\n        405       0.46      0.75      0.57       330\\n        406       0.36      0.46      0.40       263\\n        407       0.27      0.46      0.34       203\\n        408       0.24      0.18      0.21       272\\n        409       0.17      0.18      0.17       287\\n        410       0.50      0.03      0.05       251\\n        411       0.86      0.26      0.40       264\\n        412       0.52      0.04      0.07       284\\n        413       0.12      0.68      0.20       179\\n        414       0.60      0.01      0.02       244\\n        415       0.18      0.65      0.29        48\\n        416       1.00      0.02      0.03       249\\n        417       0.59      0.10      0.17       236\\n        418       0.70      0.09      0.16       232\\n        419       0.71      0.04      0.07       273\\n        420       0.05      0.16      0.08        87\\n        421       0.04      0.83      0.08        12\\n        422       0.09      0.55      0.15        69\\n        423       0.27      0.15      0.19       189\\n        424       0.27      0.04      0.07       240\\n        425       0.00      0.00      0.00        89\\n        426       0.10      0.12      0.11       442\\n        427       0.55      0.11      0.19       566\\n        428       0.40      0.19      0.26       274\\n        429       0.61      0.07      0.12       333\\n        430       0.62      0.21      0.32       268\\n        431       0.73      0.34      0.47       289\\n        432       0.51      0.21      0.30       275\\n        433       0.13      0.15      0.14       158\\n        434       0.29      0.09      0.13       222\\n        435       0.74      0.03      0.05       491\\n        436       0.25      0.18      0.21       229\\n        437       0.38      0.10      0.16       263\\n        438       0.27      0.15      0.19       248\\n        439       0.23      0.39      0.29       213\\n        440       0.17      0.46      0.25       185\\n        441       0.14      0.28      0.19       224\\n        442       0.11      0.16      0.13       204\\n        443       0.45      0.05      0.09       304\\n        444       0.42      0.14      0.21       270\\n        445       0.21      0.01      0.03       271\\n        446       0.05      0.18      0.08       256\\n        447       0.12      0.09      0.10       247\\n        448       0.25      0.21      0.23       233\\n\\navg / total       0.32      0.19      0.18    103035\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss_naive_report = classification_report(y_test, gauss_naive_predictions)\n",
    "gauss_naive_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Decision-Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=261,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=499, min_samples_split=259,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=101,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree_model = DecisionTreeClassifier(max_depth= 261, min_samples_leaf=499, min_samples_split=259, random_state=101)\n",
    "dtree_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtree_predictions = dtree_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.382200223225\n"
     ]
    }
   ],
   "source": [
    "dtree_accuracy = dtree_model.score(x_test, y_test)\n",
    "print(dtree_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       ..., \n",
       "       [  0,   0,   0, ..., 114,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,  88,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,  92]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree_cm = confusion_matrix(y_test, dtree_predictions)\n",
    "dtree_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you like to see heat map of confusion matrix , run the below cell!!! My laptop is very slow to process them all! [remove the multi line comment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure(figsize=(15,15))\\nsbn.heatmap(dtree_cm, annot=True, fmt='.3f', linewidths= 0.5, square = True, cmap= 'Blues_r');\\nall_sample_title = 'Acurracy score: {0}'.format(dtree_accuracy)\\nplt.title(all_sample_title, size= 15);\\n\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "plt.figure(figsize=(15,15))\n",
    "sbn.heatmap(dtree_cm, annot=True, fmt='.3f', linewidths= 0.5, square = True, cmap= 'Blues_r');\n",
    "all_sample_title = 'Acurracy score: {0}'.format(dtree_accuracy)\n",
    "plt.title(all_sample_title, size= 15);\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tiny Ants\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "dtree_report = classification_report(y_test, dtree_predictions)\n",
    "dtree_report;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier(n_estimators=100, max_depth=261, min_samples_leaf=499, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tiny Ants\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=261, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=499, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=101, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_forest.fit(x_train ,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rand_forest_predictions = rand_forest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#l = rand_forest.predict_proba(x_test)[0:10]\n",
    "#l;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50177124278157903"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_forest_accuracy = rand_forest.score(x_test, y_test)\n",
    "rand_forest_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       ..., \n",
       "       [  0,   0,   0, ...,  53,   0,   0],\n",
       "       [  0,   0,   0, ...,   0, 194,   0],\n",
       "       [  0,   0,   0, ...,   0,   1,  66]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_forest_cm = confusion_matrix(y_test, rand_forest_predictions)\n",
    "rand_forest_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tiny Ants\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "rand_forest_report = classification_report(y_test, rand_forest_predictions)\n",
    "rand_forest_report;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you like to see heat map of confusion matrix , run the below cell!!! My laptop is very slow to process them all! [remove the multi line comment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure(figsize=(15,15))\\nsbn.heatmap(rand_forest_cm, annot=True, fmt='.3f', linewidths= 0.5, square = True, cmap= 'Blues_r');\\nall_sample_title = 'Acurracy score: {0}'.format(rand_forest_accuracy)\\nplt.title(all_sample_title, size= 15);\\n\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "plt.figure(figsize=(15,15))\n",
    "sbn.heatmap(rand_forest_cm, annot=True, fmt='.3f', linewidths= 0.5, square = True, cmap= 'Blues_r');\n",
    "all_sample_title = 'Acurracy score: {0}'.format(rand_forest_accuracy)\n",
    "plt.title(all_sample_title, size= 15);\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Layers API based Dense Neural Network Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing one hot encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_dict.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343449, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for one_hot encoding - reshaping\n",
    "y_labels = y_labels.values.reshape(343449,-1)\n",
    "y_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "dummy = OneHotEncoder(categorical_features= [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one_hot encode\n",
    "y_labels = dummy.fit_transform(y_labels).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343449, 449)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data_dict, y_labels, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>89</th>\n",
       "      <th>9</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76780</th>\n",
       "      <td>-100</td>\n",
       "      <td>-81</td>\n",
       "      <td>-100</td>\n",
       "      <td>-58</td>\n",
       "      <td>-50</td>\n",
       "      <td>-69</td>\n",
       "      <td>-64</td>\n",
       "      <td>-82</td>\n",
       "      <td>-100</td>\n",
       "      <td>-81</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-87</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318851</th>\n",
       "      <td>-80</td>\n",
       "      <td>-51</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-66</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-65</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-77</td>\n",
       "      <td>-73</td>\n",
       "      <td>-70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327610</th>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-85</td>\n",
       "      <td>-100</td>\n",
       "      <td>-69</td>\n",
       "      <td>-72</td>\n",
       "      <td>-61</td>\n",
       "      <td>-58</td>\n",
       "      <td>-57</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168927</th>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327537</th>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 261 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1    10   101   102   103   104   105   107   109    11  ...   \\\n",
       "76780   -100   -81  -100   -58   -50   -69   -64   -82  -100   -81  ...    \n",
       "318851   -80   -51  -100  -100  -100  -100  -100  -100  -100   -66  ...    \n",
       "327610  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  ...    \n",
       "168927  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  ...    \n",
       "327537  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  ...    \n",
       "\n",
       "          89     9    90    91    92    93    94    97    98    99  \n",
       "76780   -100   -87  -100  -100  -100  -100  -100  -100  -100  -100  \n",
       "318851  -100   -65  -100  -100  -100  -100  -100   -77   -73   -70  \n",
       "327610   -85  -100   -69   -72   -61   -58   -57  -100  -100  -100  \n",
       "168927  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  \n",
       "327537  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  \n",
       "\n",
       "[5 rows x 261 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240414, 261)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240414, 449)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103035, 449)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_feat = 261\n",
    "num_hidden1 = 200\n",
    "num_hidden2 = 200\n",
    "num_hidden3 = 300\n",
    "num_hidden4 = 300\n",
    "num_hidden5 = 250\n",
    "num_hidden6 = 250\n",
    "num_hidden7 = 100\n",
    "num_outputs = 449"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,num_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.float32, shape=[None,449])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activ_fn = tf.nn.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden1 = fully_connected(x, num_hidden1, activation_fn=activ_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden2 = fully_connected(hidden1, num_hidden2, activation_fn=activ_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden3 = fully_connected(hidden2, num_hidden3, activation_fn=activ_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden4 = fully_connected(hidden3, num_hidden4, activation_fn=activ_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden5 = fully_connected(hidden4, num_hidden5, activation_fn=activ_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden6 = fully_connected(hidden5, num_hidden6, activation_fn=activ_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden7 = fully_connected(hidden6, num_hidden7, activation_fn=activ_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = fully_connected(hidden7, num_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.softmax_cross_entropy(onehot_labels=y, logits=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = 1000\n",
    "batch_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[i] for i in idx]\n",
    "    labels_shuffle = [labels[i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm worked upto 68% accuracy but after making batches of data, there was some kind of Key error, which I could not resolve unfortunately!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(batch):\n",
    "        x_train, y_train = next_batch(batch_size, x_train, y_train)\n",
    "        sess.run(train, feed_dict={x: x_train, y: y_train})\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print('accuracy on {} step:'.format(i))\n",
    "            logits = output.eval(feed_dict={x:x_test})\n",
    "            pred = tf.argmax(logits, axis=1)\n",
    "            #res = pred.eval()\n",
    "            true = tf.argmax(y, axis=1)\n",
    "            equal = tf.equal(pred, true)\n",
    "            accuracy_layers = tf.reduce_mean(tf.cast(equal, tf.float32))\n",
    "            print(sess.run(accuracy_layers, feed_dict={x: x_test, y: y_test}))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Naive bayes algorithm = 19% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree = 38% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest = 50% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Neural network = 68 % accuracy [but will improve on more training]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN algorithm did not work well for such large data sets!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression took long time to train eventhough it was split into tiny batches. So could not get good accuracy score in the given time period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have tried the entire project in estimator API. It generated the systems errors, which according to stack overflow is a error in tensor flow version."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
